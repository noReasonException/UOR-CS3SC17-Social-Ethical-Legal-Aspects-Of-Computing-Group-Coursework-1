# **Social, Legal and Ethical Aspects of Computing (CS3SC17)**

# **Group Film Analysis Report**

James Phillips 26009946

Josh Buckle

Laurence O&#39;Connor

Leo Wang

Stefanos Stefanou

Tom Merrick

3rd December 2020

**Actual Hours Spent:**  **Need to complete this**

**Assignment Evaluation:** Interesting, thought-provoking, caused further research.

Found different viewpoints and observations within the group.

Opportunity to collaborate with a new team.

# Contents

#

**[Contents 2](#_Toc57839670)**

**[Introduction 3](#_Toc57839671)**

**[Analysis 4](#_Toc57839672)**

[**Replicants – Bio Engineering (Cloning and what it is to be human)** 4](#_Toc57839673)

[**Image Analysis (Surveillance and Facial Recognition / Data Access)** 7](#_Toc57839674)

[**Autonomous Self-Driving Vehicles** 11](#_Toc57839675)

[**Social Issues Raised** 11](#_Toc57839676)

[**Legal Issues Raised** 12](#_Toc57839677)

[**Ethical Issues Raised** 12](#_Toc57839678)

**[Conclusion 14](#_Toc57839679)**

**[Reflection 14](#_Toc57839680)**

**[References and Sources 15](#_Toc57839681)**

[**References** 15](#_Toc57839682)

# Introduction

Blade Runner is a 1982 film based on the science fiction novel &quot;Do Andriods Dream of Electric Sheep?&quot; authored by Philip K. Dick. The film is set in the near future of 2019 (near-future at the time of release).

The core plot of the film involves a semi-retired law enforcement official (Deckard) being given a special mission – to eliminate a group of rogue replicants. Replicants are genetically engineered human-like creatures designed to live only a few years. Enslaved, the replicants are used a labour of other planets. This group have rebelled and escaped back to earth seeking to increase their lifespan, and Deckard is required to kill them all, which he does all but one – falling in love and sheltering the replicant Rachel.

The film brings to the fore some troubling questions around AI and cloning, forcing us to answer the question – what does it mean to be human? If it looks human, acts human, but we made it, then can we kill it like one would kill a process or scrap a vehicle?

Blade Runner shows a future with advanced technologies, including database access, image enhancement and flying cars. Whilst we&#39;re not regularly flying as our commute in 2020, significant parallels can be drawn to autonomous self-driving vehicles and questions asked as to where responsibility, accountability and ultimately liability exists in this area.

This report tackles three themes exposed in the film, either directly or as a result of the group analysing a technology seen and drawing a parallel (as with autonomous self-driving vehicles) with technology of 2020. These four themes are:

- &quot;Bio Hacking&quot;– from manufacture of biological species to sentient AI – what protections should be afforded, where is the &quot;line&quot; drawn.

- Surveillance and Image Analysis – availability, usage and processing of image data.

- Autonomous Self-Driving Vehicles – the moral hazards associated with fault.

For each theme, we have attempted to take the parallel to 2020 issues and explore the positive and negative aspects in a balanced manner, showing the impact that new technologies have on individuals, businesses, communities and globally. We also explore the possible social impact.

We conclude the report by summarising the views and the observations made, along with our collective attitude towards the themes raised by Blade Runner after analysis. We also include a section reflecting on the process of creating the report and changes we&#39;d make in a future similar project.

# Analysis

## **Replicants – Bio Engineering (Cloning and what it is to be human)**

The replicants are androids, produced by advances in bio-engineering. Whilst looking like, and thinking like humans to a point, the replicants have differ in their psychological traits to real humans. One such aspect is their emotional response to stimuli, this makes them dangerous to humans as a result of unforgiving mentality, strength and lack of remorse. Another aspect is the inability of replicants to form memories, this contributes to them being ruthless and lacking empathy.

The Turing Test (called the Voigt-Kampff test in the movie) is employed by Deckard to determine if a subject is human or replicant, asking a series of questions and gauging the emotional responses to them.

As the AI replicants in the film appear to be experiencing pain, negative emotions and a fear of death – we are forced to consider If this is a &quot;being&quot; which should fall under the same ethical code protections afforded to humans.

The replicants clearly have an underdeveloped emotional state, making them very dangerous to humans despite being created by humans. So, we have opposing dynamics, the humans perceive the replicants as being objects lacking the ability to learn empathy and to assimilate into society, which clashes with the replicants inability to understand a human&#39;s worth. Therefore, as it seems likely that the replicants will not comprehend morality and ethics to the level that human society depends upon, there cannot be a harmonious state.

Blade Runner makes this especially challenging compared to other AI such as Hal 9000 in 2001 a Space Odyssey, or the interplanetary visitors from It Came From Outer Space, Close Encounters of the Third Kind and E T – The Extra Terrestrial – where these did not have the human form. One key question is how should something that looks human, to all purposes is biologically human, but is made in a lab be treated compared to a &quot;born&quot; human, and especially when the &quot;born&quot; human is has significant cognitive impairments – society norms, ethical codes and laws provide for care and protection for these vulnerable members of society, why not for the replicants?

**Social Issues Raised**

The film presents a dystopian landscape shaped by corporate influence, we find the city of Los Angeles decrepit and polluted with the wealthiest living high above the poor. The CEO of the company that produces replicants lives on the 700th floor of a building – the poorest in society live much lower. This presents parallels to the slave trade of a few hundred years ago, where slave traders and owners would live in luxury but didn&#39;t share that wealth with the wider community.

The ability to delegate dangerous work to humanoid &quot;robots&quot; with human mobility, and human-like intelligence would be a positive, freeing people from this work, in the film the work is carried out to make other planets more hospitable for humans. However, a negative aspect of any programme of automation is the risk of leaving the human workers who used to perform the activity for pay, without wages. This in-turn can lead to a degradation in the general quality of life for these people. The same has been seen in recent times as industry has moved out of areas in the UK and other places in the world, leaving economic misery for the remaining peoples, with those who can afford to moving away (just as those who could afford to move to other planets in the film).

Replicants in the film are firmly presented as being lower class, they are used as slaves and have virtually no rights, particularly on Earth where they are totally forbidden and are to be &quot;retired&quot; as soon as they arrive considering they are trespassing. They have no option to decide their own career and are produced to serve a single role. Here we are seeing that society swings towards a class-based society, in this instance at the bottom of the hierarchy are replicants. From a social perspective, mobility is reflected in substantial implications for overall economic development. [1] A lack of mobility will entrench sections of the population in poverty, which is reflected in the film.

**Legal Issues Raised**

In the film, the company that design and then manufacture the replicants are the Tyrell Corporation. In the film they are stated to be the only manufactures of replicants meaning that they have a complete monopoly over that market. In the United Kingdom for example, Companies are penalised for any anti-competitive conduct by the Office of Fair Trading under the Enterprise Act 2002 [2]. This is enforced so that corporations like Tyrell cannot have complete control over that market and increase production of replicants to a unreasonable level, deterring other companies from entering into the replicant market in fear of being unable to compete with them. This monopoly may also mean that technology in the replicant field will most likely fail to advance as fast as a competitive market. This is due to companies competing with each other and wanting to attract more sales by having the more advanced replicant compared to their competitors leading to an urgency to improve and enhance their replicants.

In the film, it shows that if a replicant was to kill a human then it is considered murder. This shows that the murder laws that apply to humans in the movie also apply to the replicants. Under United Kingdom laws, murder can only be committed by a &#39;person&#39;, therefore if this movie was to be set in the United Kingdom then it would be assumed that the replicants in this case are treated as human. If this were true then it brings up another point, if they are treated legally the same as humans, does forcing them into labour count as enslaving them, breaching the Modern Slavery Act 2015.

**Ethical Issues Raised**

In the film, replicants are considered lower class and lesser beings than the average human. The movie portrays replicants in relation to slavery, for example the film forces the replicants to be enslaved and restricted to one role from their &#39;birth&#39; or creation. One replicant in the movie is a &#39;pleasure bot&#39; for military use, likely to keep the military staff entertained. This is an obvious example of slavery, but if they are machines developed by humans - do we not have a right to use them as we see fit?

A humanoid robot named Sofia has been developed in Hong Kong in 2018, this has &quot;embarked on a distinguished career in marketing&quot; [3] and has even been granted citizenship in Saudi Arabia. However, this has received backlash from some scientists who claim that giving robots legal status would affect human rights and is seen as &quot;inappropriate&quot;. The article on Sofia also mentions how robots may be granted &#39;robot rights&#39; when they develop conscious thought like humans.

This gives us the ethical question at what point do we consider a being as human? If no test (objective or subjective) can show this for certain – then is a given replicant that is indistinguishable from a human therefore a human? Which leaves us with the wider ethical question around intelligence and any learning or emotional impairment. The film alludes to the fact that replicants have a lack of ability in learning empathy and the subtext is that this is part of what makes them non-human. Ethically, we cannot treat a learning or otherwise disabled human as &quot;less&quot;, so do we need to hold a similar code of ethics for sentient beings such as the replicants despite their &quot;flaws&quot;?

**Should we have Replicants?**

Replicants with high functioning artificial intelligence at first look continues to appear science fiction. Although we have had the ability to successfully clone animals for nearly 25 years (Dolly the Sheep, 1996) we are yet to clone a human – but clearly the technology could exist soon, limited by law and ethical concerns rather than practicalities. In some respects, having the ability to clone or replicate has attractions – being able to have clone armies or as in the film workers for dangerous work would spare humans, possibly create a greater economy with more leisure time as low-level and manual work could be accomplished by the replicants.

However, we cannot escape the ethical questions – how could we treat a biologically cloned replicant any different to their template human? If we remove rights due to defects, then where do we stop. Cloning has any number of possible issues from rendering peoples unemployed and unemployable through to deepening an economic divide between richer and poorer people. Without a statute (laws) and clear ethical codes we cannot consider the creation of replicants and should be cautious of the effects of anthropomorphising robots, until we can clearly legislate on what &quot;personhood&quot; means.

## **Image Analysis (Surveillance and Facial Recognition / Data Access)**

From one scene Esper &quot;Enhance&quot;, we have a number of possible parallels to 21st century privacy and related concerns. The scene in question features Blade Runner – Rick Deckard deciding to examine more closely a photograph confiscated from a replicants (Leon) hotel room. As well as examining by eye, he places the photograph into an Esper machine which performs further analysis. The Blade Runner press kit from the 1982 release describes an Esper as &quot;A high-density computer with very powerful three-dimensional resolution capacity. The police cars and Deckard&#39;s apartment contain small models which can be channelled into the large one at police headquarters&quot; [4].

This scene brings about questions around modern day technology such as CCTV (Closed Circuit Television) and image capture technology, and how pervasive this is. The fact that the movie shows access from a home and mobile device indicates that such analysis is freely available.

Later in the film. Deckard reviews a recording of an apartment he investigated earlier. The data is shown on his personal television and controlled by voice. Critically, again it seems that there are no access controls for the data (the recording) – Deckard has not been required to demonstrate why he needs such access, which is being made from a non-secure location. The footage that is enhanced (image analysis and enhancement), is then printed, which makes sense in the plot of the film, but again raises various concerns.

Overall, we see a focus on the investigation with little regard to the confidentiality of data (in this case CCTV type footage). In the context of the film, where Decker is ostensibly &quot;chasing the bad guys&quot; this is easy to overlook. However, the ease at which data is accessed and the enhance feature poses questions for us in the real 2020, with a prevalent CCTV culture and suitably advanced facial recognition systems.

**Social Issues Raised**

In today&#39;s society with 4-5.9 million CCTV cameras in the UK - 2015 estimate by BSIA (British Security Industry Association) [5] we are subject to being observed and recorded in many populated areas, whilst proponents say that crime is reduced, others argue that it is mass surveillance.

&quot;The potential value of public surveillance technology was well demonstrated in April, 2013 when investigators identified the two suspects in the Boston Marathon bombing after sifting through video images captured by the city&#39;s cameras.

The Boston bombers were apprehended quickly due to surveillance cameras. While there is no dispute over how well the public cameras worked on that day, many lingering questions remain and will continue to drive debate for the foreseeable future.&quot; [6]

From a social aspect, CCTV is typically regarded as a positive, a deterrent reducing anti-social behaviour and generally making people feel safer. &quot;The summer of 2011 riots undoubtedly strengthened public opinion towards CCTV. In one post-riots survey of two thousand adults, three quarters of respondents said they &#39;felt safer&#39; in public areas knowing CCTV was in operation, two thirds wanted to see more CCTV in their area, and seven out of 10 would be &#39;worried&#39; if their local council reduced CCTV coverage. 94 per cent of those surveyed backed the police using CCTV footage to identify those involved in the riots.&quot; [7]

The evidence for success is less compelling, of 4000 images subjected to facial recognition after the summer 2011 riots, only one arrest was made. [8]. Whereas in Airdrie, in the 2 years following installation of cameras a reduction in offences of 48% occurred, with little evidence of the crime simply moving &quot;out of sight&quot;. [9], in Glasgow, in the year following installation of cameras saw slight reductions, but an overall increase of crime by 9% [10] and in Birmingham, theft from persons was reduced, but theft from vehicles increased after installation of cameras in the early 1990s. [11].

**Legal issues Raised**

Legally, the UK in 2020 covers the data captured by CCTV and other forms of surveillance cameras as data, under the Data Protection Act / GDPR. However, specific covert surveillance activities of public authorities are not covered but rather they are governed by the Regulation of Investigatory Version 1.2 8 20170609 Powers Act (RIPA) 2000 and Regulation of Investigatory Powers (Scotland) Act (RIPSA) 2000. Critically this type of recording is covert and directed at an individual or individuals – so does not cover &quot;mass surveillance&quot;.

Access to a wide range of images is key to the success of an investigation such as that portrayed in the film. As we have mentioned previously, this does not seem to require authorisation – and the fact that the images are &quot;enhanced&quot; gives rise to a concern that the enhancement is changing the recorded fact. In the film, this is not the case – but recent developments in plenoptic cameras which can collect sufficient light data to recreate 3D models of suspects and even adjust the viewing angle of a picture after it has been taken means that we have the situation where technology may &quot;enhance&quot; evidence to the point that it is altered.

In other scenes, Deckard has access to information about the subjects he is pursuing. The intimation here is that there is a database of individuals readily accessible and used without constraint. When you consider the array of data known by various government agencies about you as an individual, it is not difficult to imagine this being combined into a very revealing consolidated database. Whilst researching this, we found that there are clear boundaries and the various agencies act within the confines of the Data Protection Act.

However, a prior case exists where the UK government has misused data, albeit in a pre-computing era. In 1939 a national identity card scheme was introduced by the National Registration Act for the purpose of security, national service and rationing. By 1950 the same cards were being used by 39 government agencies for reasons as diverse as collecting parcels from the post office to routine police enquiries. While any or even all of these were arguably justified, few could be justified under the terms of the initial Act. It was a combination of protest and the eventual recognition of this extension of use which led to the abolition of the Act that same year. [12]

The issue here is the extension of technology employed for one reason, into repeated and regular use in another area which may not have been subjected to the appropriate scrutiny.

**Ethical Issues Raised**

Who has access is an interesting ethical item, police and security services can request and access footage from other operators and in an investigative capacity (tracing a suspects movements whilst investigating a prior crime, or indeed acting on intelligence and aiming to prevent a crime) this would be almost universally acceptable. However, we must ask where is the boundary, with advances in Facial Recognition – does an expert operator need to be the one that follows the movements, or can a computer do this? If we accept that a computer can follow the suspect and report on their movements reliably – we now have an ethical problem - Should we use automated image capture and facial recognition to inform and attempt to prevent crime? Especially as the computer can cheaply scale to put ever increasing numbers of citizens under surveillance.

Well controlled, audited and managed data should pose no threat to the individual. The Data Protection Act enshrines this in law, and on the assumption that the CCTV operating entities follow the legislation there is little to fear. However, we should take the case where facial recognition could be used to build a &quot;network&quot; of contact for a person-of-interest. With so many sources of data for photographs available (DVLA for driving licences, Passport Office, Social Media as well as specific images from criminal records and targeted investigations) there is a risk of technology categorising a person incorrectly.

**Should Law Enforcement Have Unrestricted Access to Data?**

Generally, we have become a more voyeuristic society, not only with CCTV, but reality television, social media as well. We are now used to our imagery being captured and published on a macro scale. Therefore, if my friends and their friends can see my social media pictures, why if I have nothing to hide am I worried about my images being viewed? The same argument can be made for the other data held by corporations and government departments – there is an argument that if I have nothing to hide then I have nothing to fear. If data access such as CCTV assists in catching those responsible for crime, then it is a force for good.

However, there are key differences - as an individual we decide to partake in a reality television show, we generally agree to share via social media (agreement in the wider context, by joining the site). In terms of CCTV and image capture positively making individuals feel safer, the concern is that the evidence is mixed. Although useful in solving some crime, it is not clear that there is an impact aligned to the &quot;feeling&quot; of safety, at the cost of personal privacy. The risks of misuse of data must be considered, what is to stop inappropriate review of data without safeguards? Also, we must question the increasing use of automation and analysis by computer in law enforcement, feeding huge amounts of data into unchecked programs may have poor consequences based on logical reasoning alone. For example:

Person A meets person B in the street and they have a brief conversation, person B then meets person C a suspected terrorist. Should we tag person A as being of interest, a potential threat? Should we record the interaction in a database, later to be cross referenced without the context of the interaction? That would be particularly scary if one of us was person A, and we&#39;d been asked for directions by unknown person C!

Therefore, it is essential that proper safeguards exist to allow use of data including images in a controlled and appropriate manner but preventing widespread risk of misuse.

## **Autonomous Self-Driving Vehicles**

In the film, the cars fly and have aircraft style controls. In 2020, we don&#39;t have flying cars, but we do have autonomous self-driving vehicles. We have drawn a parallel between these technologies – clearly over 38 years technology has diverged from the supposed path – but we believe the link to be valid. Of note, the first view of the flying car (called a Spinner) is in a scene where an unseen announcer says over a loudspeaker that better life awaits humans in the off world colonies – interesting in that one of the leading manufacturers of self-driving cars in 2020, Tesla is headed by Elon Musk, who at Space X has ambitions to place one million people on Mars by 2050.

An autonomous self-driving car would appear to be an obvious &quot;good idea&quot;, especially when one reads of a person killed or injured as a result of drunk or careless driving, as surely a self-driving vehicle won&#39;t be intoxicated or performing a risky, careless manoeuvre.

## **Social Issues Raised**

The social considerations of self-driving cars are interesting, we have on the one hand increased safety, likely ability to drive smart (e.g. reducing emissions) to work collaboratively to optimise traffic flows and therefore reduce journey times. On the other hand, as will all new technology there exists a premium price for early adopters, discriminating between those who can and cannot afford a self-driving car, with such inequality potentially compounded when we consider the worker arriving at the office relaxed and well informed, having being driven their by their car, reading the latest company reports along the way; compared to the driver who has a daily battle through traffic, in an unreliable car, worrying about being late – who&#39;s going to succeed that the company and be promoted?

Local taxis are another area of concern, self-driving taxis offer the societal impact of smaller, efficient &quot;pod&quot; like transport from point-to-point, at the expense of a livelihood for taxi drivers. In the past ten years, Uber and Lyft have changed the way we request and pay for taxi services. Removing the driver may be the very next step. Similar arguments exist for buses and trains – further automation will render the drivers redundant or reduce them to a lower-level role (e.g. train guards).

From a social perspective, we have the possibility of safer, cleaner, more efficient transport – but at the cost of livelihoods. Can it be right to make people poorer as automation takes more and more &quot;jobs&quot; or are we moving the humans into disparate roles some building and creating the &quot;robots&quot; and some working alongside them.

In a 2015 report by McKinsey and Company, evidence shows that self-driving cars will dramatically decrease car accidents by up to 90%, prevent up to $190 billion in damages and health-costs annually, and save thousands of lives. [13] Can we say that saving thousands of lives is a bad thing? But we must relate this to the societal impact. How much of the $190 billion would be wages for workers involved in assessing, processing and carrying out repairs to damaged vehicles.

## **Legal Issues Raised**

Legally, the position on self-driving vehicles is an emerging field. Currently, the responsibility remains with the &quot;driver&quot; even though the car may be driving itself, in the United Kingdom the use of &quot;autopilot&quot; type systems is not legal, with a current consultation underway around the use of automated lane keeping and speed sensing systems, the law says that drivers must remain alert and ready to take over instantly.

An interesting legal aspect of self-driving cars comes when one explores the apportionment of blame in the event of an accident. Clearly, an advantage of self-driving cars is the ability to compute quickly data from many senses and not to suffer from any fatigue or distraction. However, in the event of an accident, who is responsible the &quot;driver&quot;, the &quot;owner&quot;, the manufacturer? Especially sensitive in the case where the cause is a software defect, or corner-case unexpected and unhandled.

## **Ethical Issues Raised**

Ethically, we must consider what occurs when a self-driving car is involved in a crash. A human is able to forgive, there is a recognition that we are pre-programmed to protect ourselves. Therefore, the driver who swerves to avoid an oncoming vehicle and hits a parked car is quickly forgiven. However, there is a view that a self-driving car will not be treated in the same way as the machine has not reacted, it has followed a set of deliberate actions resulting in the same outcome. [14]

Self-driving cars are being setup to make ethical choices, or perhaps more appropriately ethically compatible choices. Self-driving cars are worked on by some of the smartest people hired by companies such as Google that seek to hire from the smartest people anyway. Many years of research and development have gone into improving the technology in this area. For example, &quot;When a self-driving car sees a cyclist, it would move slightly over in its lane to give the cyclist more space. Google&#39;s algorithm calculates the probability by risk magnitude, compares it to the value of information to be gained, and uses that to make decisions. Getting sideswiped by a truck has a risk magnitude of 5,000, getting into a head-on crash with another car has a risk magnitude of 20,000, and hitting a pedestrian has a risk magnitude of 100,000&quot;. [15] Using a points-based system, the self-driving car attempts to make the same choice as an ethical human would.

Germany attempted to solve the ethical issues of self-driving cars with actual guidelines. The nation proposed that: &quot;self-driving cars should always attempt to minimize human death and shouldn&#39;t discriminate between individuals based on age, gender, or any factor. Human lives should also always be given priority over animals or property&quot;. [16] Can a state really govern what is ethical based on a precedent rule?

It is possible to argue that &quot;random&quot; accidents are more justified than the output of a determinate algorithm, especially if that leads to the death or injury of someone in a car crash. Some believe that the situation is too complex, and people should just allow accidents to naturally happen, it being unethical to make decisions on another person&#39;s life.

In the case of self-driving cars, engineers developed the technology based on their ethics. The decisions and ethics of the designers and engineers influence the lives of passengers, bystanders and occupants of other vehicles. This can be considered as unethical, in that one should not be controlled by others.

The ethical dilemma around self-driving cars can be described by the Trolley Problem.

There is a runaway trolley barrelling down the railway tracks. Ahead, on the tracks, there are five people tied up and unable to move. The trolley is headed straight for them. You are standing some distance off in the train yard, next to a lever. If you pull this lever, the trolley will switch to a different set of tracks. However, you notice that there is one person on the side-track. You have two options:

1. Do nothing and allow the trolley to kill the five people on the main track.
2. Pull the lever, diverting the trolley onto the side-track where it will kill one person.

Which is the more ethical option? Or, more simply: What is the right thing to do? [17]

From a utilitarian perspective, the right thing to do is to pull the leaver and save the most people. However, there is an alternative view that whilst there is already a situation with moral wrongs, pulling the leaver is participation in a moral wrong. However, under interpretations of moral obligation [18] simply being in the position where one can act, means that one should act, compelling the pulling of the leaver. The same choice faces those programming the collision options and decision making in self-driving vehicles.

**Should we Allow Self-Driving Cars?**

With a planet with a climate crisis, anything that can move towards less emissions, better economy and that can be coupled with less risk, less accidents must be considered positive. We&#39;d argue that the legal aspect simply needs to be resolved, if the driver is AI – then the manufacturer should be responsible or insured just like a current human driver is. The moral hazards presented are real but must be edge-cases in the greater scheme of things, we cannot wait for perfect when a better than good-enough solution exists.

Whilst there is no question that self-driving cars and other autonomous vehicles have an advantage, we have not as yet reached the point where the questions over the decisions made by the AI in these vehicles can be trusted. We have to consider the accountability and responsibility and have clarity on this before allowing these vehicles to operate autonomously. The current legislation is clear, the driver is responsible and liable following an accident, not the manufacturer (except in very specific circumstances) or the owner. Until we can find an acceptable solution to the Trolley Problem, be that through judicial review or by public consensus, we have the issue as to fault and the moral hazard.

As with any automation, we must fix the problem of unemployment or more accurately, the societal issues of lack of employment and therefore funds. Self-driving vehicles will remove more jobs from the economy, without support this presents a real risk.

# Conclusion

Blade Runner paints a possible picture of a 2019 life. On first watching the film, we were taken aback by the level to which a near future prediction could be so inaccurate (replicated beings, flying cars, colonisation of other planets). However, by collectively and individually noting scene by scene technology, we found ourselves discussing significant parallels with the world in 2020. Flying cars, with pilot type controls became autonomous self-driving vehicles, image analysis or enhancement became the use of technology in surveillance, replicants became cloning and a wider question re: sentient AI. Each topic raised various social, legal and ethical issues.

This begs the question that just because we can, should we? Especially when employing advanced technology – self-driving cars seems so obvious, every time we read of deaths or injuries caused by drunk or careless drivers taking the human driver out of equation sounds like the solution. But the reality provides us with a further set of questions – when the decision making engine in the car has to determine risk and decide between protecting the occupants of the car, or the reckless, illogical human who is crossing the street in a dangerous manner – who is responsible, the owner, the passenger(s), the manufacturer, the individual software developer who wrote the code?

Ultimately, we conclude that the continued quest for &quot;better&quot; is a good thing, greater safety, better analysis to solve and even prevent crime, the removal of human bias from decision making – all have a key role in 2020 and beyond, but the use of technology must be well governed, and must not move ahead of a system of law and corresponding acceptable ethical considerations.

Lastly, we now wonder if the original novel&#39;s title was a clue to the topics raised or just a catchy title – Do androids dream of electric sheep?

# Reflection

In completing this exercise, we have worked as a team, we initially we undecided on the film to use. We spent time watching individual films and then discussed – deciding on Blade Runner and then watching. Whilst this led to a good debate on various plots, uses of technology and social, ethical and legal standpoints, on reflection we should have made a choice sooner and had more time to debate.

Given a large number of points to investigate we would select the film earlier should the task be repeated. We would then have had more opportunities to select from the wide number of possible tracks and investigate. As technologists we found it interesting in the final stages of the report that not being together in a group setting was proving difficult, despite Teams calls and collaborative workspaces, we concluded that more in-person face-to-face time would have fostered better and certainly easier debate and flow of ideas. Subject to COVID restrictions we would have done this.

# References and Sources

## **References**

[1] [https://penniur.upenn.edu/index.php/publications/improving-opportunities-for-social-mobility-in-the-united-states#:~:text=Children%20from%20disadvantaged%20backgrounds%20naturally,example%20by%20reducing%20transfer%20payments](https://penniur.upenn.edu/index.php/publications/improving-opportunities-for-social-mobility-in-the-united-states#:~:text=Children%20from%20disadvantaged%20backgrounds%20naturally,example%20by%20reducing%20transfer%20payments).

[2] -[https://www.delta-net.com/compliance/competition-law/faqs/what-is-the-enterprise-act-2002](https://www.delta-net.com/compliance/competition-law/faqs/what-is-the-enterprise-act-2002)

[3] [https://www.wired.co.uk/article/sophia-robot-citizen-womens-rights-detriot-become-human-hanson-robotics](https://www.wired.co.uk/article/sophia-robot-citizen-womens-rights-detriot-become-human-hanson-robotics)

[4] [http://www.brmovie.com/FAQs/BR\_FAQ\_Terminology.htm](http://www.brmovie.com/FAQs/BR_FAQ_Terminology.htm) [Accessed 29-11-2020]

[5] [https://www.bbc.co.uk/news/uk-30978995#:~:text=The%20UK%20has%20one%20of,between%204%2D5.9%20million%20cameras](https://www.bbc.co.uk/news/uk-30978995#:~:text=The%20UK%20has%20one%20of,between%204%2D5.9%20million%20cameras) [Accessed 29-11-2020]

[6] [https://www.ifsecglobal.com/video-surveillance/role-cctv-cameras-public-privacy-protection/](https://www.ifsecglobal.com/video-surveillance/role-cctv-cameras-public-privacy-protection/) [Accessed 29-11-2020]

[7] [http://www.police-foundation.org.uk/2017/wp-content/uploads/2017/08/cctv.pdf](http://www.police-foundation.org.uk/2017/wp-content/uploads/2017/08/cctv.pdf) [Page 15]

[8] [https://www.ifsecglobal.com/video-surveillance/london-riots-only-1-arrest-made-as-result-of-facial-recognition/](https://www.ifsecglobal.com/video-surveillance/london-riots-only-1-arrest-made-as-result-of-facial-recognition/) [Accessed 29-11-2020]

[9] [www.scotland.gov.uk/cru/resfinds/crf08-00.htm](http://www.scotland.gov.uk/cru/resfinds/crf08-00.htm) from [https://www.parliament.uk/globalassets/documents/post/pn175.pdf](https://www.parliament.uk/globalassets/documents/post/pn175.pdf) [Accessed 29-11-2020]

[10] [www.scotcrim.u-net.com/researchc2.htm](http://www.scotcrim.u-net.com/researchc2.htm) from [https://www.parliament.uk/globalassets/documents/post/pn175.pdf](https://www.parliament.uk/globalassets/documents/post/pn175.pdf) [Accessed 29-11-2020]

[11] [www.homeoffice.gov.uk/prgpubs/fcdps68.pdf](http://www.homeoffice.gov.uk/prgpubs/fcdps68.pdf) from [https://www.parliament.uk/globalassets/documents/post/pn175.pdf](https://www.parliament.uk/globalassets/documents/post/pn175.pdf) [Accessed 29-11-2020]

[12] [https://iep.utm.edu/surv-eth/](https://iep.utm.edu/surv-eth/)

[13] Ramsey, M. (2015, March 05). Self-Driving Cars Could Cut Down on Accidents, Study Says. Retrieved from [https://www.wsj.com/articles/self-driving-cars-could-cut-down-on-accidents-study-says-1425567905](https://www.wsj.com/articles/self-driving-cars-could-cut-down-on-accidents-study-says-1425567905) [Accessed 29-11-2020]

[14] Nelson, G. (July 13, 2015). Self-driving cars make ethical choices. Automotive News Print Version. Retrieved from Nexis Uni. [Accessed 29-11-2020]

[15] Trappl, R. (n.d.). Ethical Systems for Self-Driving Cars: An Introduction. Applied Artificial Intelligence, 30(8), 745–747. [https://doi.org/10.1080/08839514.2016.1229737](https://doi.org/10.1080/08839514.2016.1229737) [Accessed 20-11-2020]

[16] Nowak, P. (2018, February 02). The ethical dilemmas of self-driving cars. Retrieved from [https://www.theglobeandmail.com/globe-drive/culture/technology/the-ethical-dilemmas-of-self-drivingcars/article37803470/](https://www.theglobeandmail.com/globe-drive/culture/technology/the-ethical-dilemmas-of-self-drivingcars/article37803470/) [Accessed 29-11-2020]

[17] https://en.wikipedia.org/wiki/Trolley\_problem

[18] https://en.wikipedia.org/wiki/Duty
