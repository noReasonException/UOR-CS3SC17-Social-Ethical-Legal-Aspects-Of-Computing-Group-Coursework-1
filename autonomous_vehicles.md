## **Autonomous Self-Driving Vehicles**

In the film, the cars fly and have aircraft style controls. In 2020, we don&#39;t have flying cars, but we do have autonomous self-driving vehicles. We have drawn a parallel between these technologies – clearly over 38 years technology has diverged from the supposed path – but we believe the link to be valid. Of note, the first view of the flying car (called a Spinner) is in a scene where an unseen announcer says over a loudspeaker that better life awaits humans in the off world colonies – interesting in that one of the leading manufacturers of self-driving cars in 2020, Tesla is headed by Elon Musk, who at Space X has ambitions to place one million people on Mars by 2050.

An autonomous self-driving car would appear to be an obvious &quot;good idea&quot;, especially when one reads of a person killed or injured as a result of drunk or careless driving, as surely a self-driving vehicle won&#39;t be intoxicated or performing a risky, careless manoeuvre.

The social considerations of self-driving cars are interesting, we have on the one hand increased safety, likely ability to drive smart (e.g. reducing emissions) to work collaboratively to optimise traffic flows and therefore reduce journey times. On the other hand, as will all new technology there exists a premium price for early adopters, discriminating between those who can and cannot afford a self-driving car, with such inequality potentially compounded when we consider the worker arriving at the office relaxed and well informed, having being driven their by their car, reading the latest company reports along the way; compared to the driver who has a daily battle through traffic, in an unreliable car, worrying about being late – who&#39;s going to succeed that the company and be promoted?

As autonomous self-driving vehicles become more prevalent, what happens to the jobs of humans who used to drive them. During the 2020 COVID-19 pandemic, with various restrictions imposed, we have turned ever more to online shopping and home deliveries as a society. Amongst the gloomy economic impact of lockdowns, more and more jobs have been created for grocery and other delivery staff – taking goods from the &quot;distribution centre&quot; to the customers&#39; homes, a journey often described as being &quot;the last mile&quot; regardless of the actual distance. Perhaps, as social consideration we should look at the stage before these &quot;last mile&quot; delivery agents. Goods are regularly routed around the UK from centralised warehouses to the distribution centres – the driving and delivery activities in this phase of the journey could easily be turned over to an autonomous self-driving vehicle, requiring no mandatory rest breaks, able to drive on and on moving goods between central locations and distribution points. What happens to these drivers? What happens to the drivers who move goods across the continent when self-driving trucks can complete the job safely without breaks.

Taking a driver working the US standard of 70 hours per week worked for a lorry driver, then clearly a self-driving truck can do at least twice the work. Using a median salary of $73,000 this gives the opportunity to &quot;save&quot; $146,000 per year. Higher initial costs reduce this saving. [9] However, it is not all simple, many activities undertaken by the driver including vehicle checks, loading and unloading and performing elements of customer service, none of which can currently by automated. [10] Meaning that there is a lower chance of the humans being replaced, although we need to consider that the role and the &quot;expertise&quot; required may diminish.

Local taxis are another area of concern, self-driving taxis offer the societal impact of smaller, efficient &quot;pod&quot; like transport from point-to-point, at the expense of a livelihood for taxi drivers. In the past ten years, Uber and Lyft have changed the way we request and pay for taxi services. Removing the driver may be the very next step.

Similar arguments exist for buses and trains – further automation will render the drivers redundant or reduce them to a lower-level role (e.g. train guards).

From a social perspective, we have the possibility of safer, cleaner, more efficient transport – but at the cost of livelihoods. Can it be right to make people poorer as automation takes more and more &quot;jobs&quot; or are we moving the humans into disparate roles some building and creating the &quot;robots&quot; and some working alongside them.

Legally, the position on self-driving vehicles is an emerging field. Currently, the responsibility remains with the &quot;driver&quot; even though the car may be driving itself, in the UK the use of &quot;autopilot&quot; type systems is not legal, with a current consultation underway around the use of automated lane keeping and speed sensing systems, the law says that drivers must remain alert and ready to take over instantly.

An interesting legal aspect of self-driving cars comes when one explores the apportionment of blame in the event of an accident. Clearly, an advantage of self-driving cars is the ability to compute quickly data from many senses and not to suffer from any fatigue or distraction. However, in the event of an accident, who is responsible the &quot;driver&quot;, the &quot;owner&quot;, the manufacturer? Especially sensitive in the case where the cause is a software defect, or corner-case unexpected and unhandled.

Ethically, we must consider what occurs when a self-driving car is involved in a crash. A human is able to forgive, there is a recognition that we are pre-programmed to protect ourselves. Therefore, the driver who swerves to avoid an oncoming vehicle and hits a parked car is quickly forgiven. However, there is a view that a self-driving car will not be treated in the same way as the machine has not reacted, it has followed a set of deliberate actions resulting in the same outcome. [11]

Self-driving cars are being setup to make ethical choices, or perhaps more appropriately ethically compatible choices. Self-driving cars are worked on by some of the smartest people hired by companies such as Google that seek to hire from the smartest people anyway. Many years of research and development have gone into improving the technology in this area. For example, &quot;When a self-driving car sees a cyclist, it would move slightly over in its lane to give the cyclist more space. Google&#39;s algorithm calculates the probability by risk magnitude, compares it to the value of information to be gained, and uses that to make decisions. Getting sideswiped by a truck has a risk magnitude of 5,000, getting into a head-on crash with another car has a risk magnitude of 20,000, and hitting a pedestrian has a risk magnitude of 100,000&quot;. [12] Using a points-based system, the self-driving car attempts to make the same choice as an ethical human would.

In a 2015 report by McKinsey and Company, evidence shows that self-driving cars will dramatically decrease car accidents by up to 90%, prevent up to $190 billion in damages and health-costs annually, and save thousands of lives. [13] Ethically, can we say that saving thousands of lives is a bad thing? But we must relate this to the societal impact. How much of the $190 billion would be wages for workers involved in assessing, processing and carrying out repairs to damaged vehicles.

Germany attempted to solve the ethical issues of self-driving cars with actual guidelines. The nation proposed that: &quot;self-driving cars should always attempt to minimize human death and shouldn&#39;t discriminate between individuals based on age, gender, or any factor. Human lives should also always be given priority over animals or property&quot;. [14] Can a state really govern what is ethical based on a precedent rule?

It is possible to argue that &quot;random&quot; accidents are more justified than the output of a determinate algorithm, especially if that leads to the death or injury of someone in a car crash. Some believe that the situation is too complex, and people should just allow accidents to naturally happen, it being unethical to make decisions on another person&#39;s life.

In the case of self-driving cars, engineers developed the technology based on their ethics. The decisions and ethics of the designers and engineers influence the lives of passengers, bystanders and occupants of other vehicles. This can be considered as unethical, in that one should not be controlled by others.

References

[9] [https://www.tuxera.com/blog/autonomous-trucks-vs-human-drivers/](https://www.tuxera.com/blog/autonomous-trucks-vs-human-drivers/) [Accessed 29-11-2020]

[10] [https://hbr.org/2019/09/automation-isnt-about-to-make-truckers-obsolete](https://hbr.org/2019/09/automation-isnt-about-to-make-truckers-obsolete) [Accessed 29-11-2020]

[11] Trappl, R. (n.d.). Ethical Systems for Self-Driving Cars: An Introduction. _Applied Artificial Intelligence_, _30_(8), 745–747. [https://doi.org/10.1080/08839514.2016.1229737](https://doi.org/10.1080/08839514.2016.1229737) [Accessed 20-11-2020]

[12] Nelson, G. (July 13, 2015). Self-driving cars make ethical choices. _Automotive News Print Version. _Retrieved from Nexis Uni. [Accessed 29-11-2020]

[13] Ramsey, M. (2015, March 05). Self-Driving Cars Could Cut Down on Accidents, Study Says. Retrieved from [https://www.wsj.com/articles/self-driving-cars-could-cut-down-on-accidents-study-says-1425567905](https://www.wsj.com/articles/self-driving-cars-could-cut-down-on-accidents-study-says-1425567905) [Accessed 29-11-2020]

[14] Nowak, P. (2018, February 02). The ethical dilemmas of self-driving cars. Retrieved from [https://www.theglobeandmail.com/globe-drive/culture/technology/the-ethical-dilemmas-of-self-drivingcars/article37803470/](https://www.theglobeandmail.com/globe-drive/culture/technology/the-ethical-dilemmas-of-self-drivingcars/article37803470/) [Accessed 29-11-2020]
